{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import warnings\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from skimage import io\n",
    "from params import dresden_images_root, images_db_path, patch_span, \\\n",
    "        patch_num, patches_root, train_db_path, test_db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_db = np.load(images_db_path, allow_pickle=True).item()\n",
    "\n",
    "model_list = np.unique(images_db['brand_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = images_db['path']\n",
    "num_test = int(len(img_list) * 0.2)\n",
    "num_train = int(len(img_list) - num_test)\n",
    "num_val = int(num_train * 0.2)\n",
    "num_train = num_train - num_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_list = np.random.permutation(img_list)\n",
    "\n",
    "train_list = shuffle_list[0:num_train].tolist()\n",
    "val_list = shuffle_list[num_train:num_train + num_val].tolist()\n",
    "test_list = shuffle_list[num_train + num_val:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canon_Ixus55 in training set: 146.\n",
      "Canon_Ixus55 in validation set: 38.\n",
      "Canon_Ixus55 in test set: 40.\n",
      "\n",
      "Canon_Ixus70 in training set: 359.\n",
      "Canon_Ixus70 in validation set: 85.\n",
      "Canon_Ixus70 in test set: 123.\n",
      "\n",
      "Canon_PowerShotA640 in training set: 123.\n",
      "Canon_PowerShotA640 in validation set: 33.\n",
      "Canon_PowerShotA640 in test set: 32.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    tmp_list = fnmatch.filter(train_list, model + '*')\n",
    "    print(\"{} in training set: {}.\".format(model, len(tmp_list)))\n",
    "    tmp_list = fnmatch.filter(val_list, model + '*')\n",
    "    print(\"{} in validation set: {}.\".format(model, len(tmp_list)))\n",
    "    tmp_list = fnmatch.filter(test_list, model + '*')\n",
    "    print(\"{} in test set: {}.\\n\".format(model, len(tmp_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(img_name, patch_span, pacth_size=(256, 256)):\n",
    "    img = io.imread(img_name)\n",
    "    if img is None or not isinstance(img, np.ndarray):\n",
    "        print('Unable to read the image: {:}'.format(args['img_path']))\n",
    "\n",
    "    center = np.divide(img.shape[:2], 2).astype(int)\n",
    "    start = np.subtract(center, patch_span/2).astype(int)\n",
    "    end = np.add(center, patch_span/2).astype(int)\n",
    "    sub_img = img[start[0]:end[0], start[1]:end[1]]\n",
    "    patches = view_as_blocks(sub_img[:, :, 1], (256, 256))\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save(args):\n",
    "    # 'Agfa_DC-504/Agfa_DC-504_0_1_00.png' for example,\n",
    "    # last part is the patch idex.\n",
    "    output_rel_paths = [os.path.join(args['data_set'], args['img_brand_model'],\n",
    "                        os.path.splitext(os.path.split(args['img_path'])[-1])[0]+'_'+'{:02}'.format(patch_idx) + '.png')\\\n",
    "                        for patch_idx in range(args['patch_num'])]\n",
    "    read_img = False\n",
    "    for out_path in output_rel_paths:\n",
    "        out_fullpath = os.path.join(args['patch_root'], out_path)\n",
    "        # if there is no this path, then we have to read images\n",
    "        if not os.path.exists(out_fullpath):\n",
    "            read_img = True\n",
    "            break\n",
    "    if read_img:\n",
    "        img_name = os.path.join(args['img_root'], args['img_path'])\n",
    "        patches = patchify(img_name, args['patch_span']).reshape((-1, 256, 256))\n",
    "        \n",
    "        for out_path, patch in zip(output_rel_paths, patches):\n",
    "            out_fullpath = os.path.join(args['patch_root'],out_path)\n",
    "            # the diretory of the patches images\n",
    "            out_fulldir = os.path.split(out_fullpath)[0]\n",
    "            if not os.path.exists(out_fulldir):\n",
    "                os.makedirs(out_fulldir)\n",
    "            if not os.path.exists(out_fullpath):\n",
    "                io.imsave(out_fullpath, patch)\n",
    "\n",
    "    return output_rel_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_labels = dict(zip(images_db['path'], images_db['brand_model']))\n",
    "\n",
    "train_labels = []\n",
    "val_labels = []\n",
    "test_labels = []\n",
    "\n",
    "for path in train_list:\n",
    "    train_labels += [files_labels[path]]\n",
    "    \n",
    "for path in val_list:\n",
    "    val_labels += [files_labels[path]]\n",
    "    \n",
    "for path in test_list:\n",
    "    test_labels += [files_labels[path]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "979it [00:00, 70851.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image data...\n",
      "Extracting patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'patches/test/Canon_Ixus55'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/gary/anaconda3/envs/cam/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/gary/anaconda3/envs/cam/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-8-bcf86c6fd305>\", line 23, in extract_and_save\n    os.makedirs(out_fulldir)\n  File \"/home/gary/anaconda3/envs/cam/lib/python3.7/os.py\", line 221, in makedirs\n    mkdir(name, mode)\nFileExistsError: [Errno 17] File exists: 'patches/test/Canon_Ixus55'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-24741e68062a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mtrain_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_and_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_imgs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mval_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_and_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_imgs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtest_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_and_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_imgs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# # Create patches dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cam/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cam/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'patches/test/Canon_Ixus55'"
     ]
    }
   ],
   "source": [
    "print('Collecting image data...')\n",
    "\n",
    "train_imgs_list = []\n",
    "val_imgs_list = []\n",
    "test_imgs_list = []\n",
    "\n",
    "for img_brand_model,img_path in \\\n",
    "    tqdm(zip(images_db['brand_model'], images_db['path'])):\n",
    "                   \n",
    "    if img_path in train_list:\n",
    "        train_imgs_list += [{'data_set':'train',\n",
    "                           'img_path':img_path,\n",
    "                           'img_brand_model':img_brand_model,\n",
    "                           'patch_span':patch_span,\n",
    "                           'patch_num':patch_num,\n",
    "                           'patch_root': patches_root,\n",
    "                           'img_root': dresden_images_root\n",
    "                           }]\n",
    "        \n",
    "    elif img_path in val_list:\n",
    "        val_imgs_list += [{'data_set':'val',\n",
    "                           'img_path':img_path,\n",
    "                           'img_brand_model':img_brand_model,\n",
    "                           'patch_span':patch_span,\n",
    "                           'patch_num':patch_num,\n",
    "                           'patch_root': patches_root,\n",
    "                           'img_root': dresden_images_root\n",
    "                           }]\n",
    "        \n",
    "    else:\n",
    "        test_imgs_list += [{'data_set':'test',\n",
    "                           'img_path':img_path,\n",
    "                           'img_brand_model':img_brand_model,\n",
    "                           'patch_span':patch_span,\n",
    "                           'patch_num':patch_num,\n",
    "                           'patch_root': patches_root,\n",
    "                           'img_root': dresden_images_root\n",
    "                           }]\n",
    "    \n",
    "print('Extracting patches...')\n",
    "\n",
    "num_processes = 12\n",
    "pool = Pool(processes=num_processes)\n",
    "train_paths = pool.map(extract_and_save, train_imgs_list)\n",
    "val_paths = pool.map(extract_and_save, val_imgs_list)\n",
    "test_paths = pool.map(extract_and_save, test_imgs_list)\n",
    "\n",
    "# # Create patches dataset\n",
    "# print('Creating patches dataset...')\n",
    "# train_dataset = dict()\n",
    "# train_dataset['path'] = []\n",
    "# train_dataset['labels'] = []\n",
    "\n",
    "# for patch_rel_paths, img_labels in tqdm(zip(train_paths, train_labels)):\n",
    "#     for patch_rel_path in patch_rel_paths:\n",
    "#         train_dataset['path'] += [patch_rel_path]\n",
    "#         train_dataset['labels'] += [img_labels]\n",
    "\n",
    "# train_dataset['path'] = np.asarray(train_dataset['path']).flatten()\n",
    "# train_dataset['shot'] = np.asarray(train_dataset['labels']).flatten()\n",
    "        \n",
    "# test_dataset = dict()\n",
    "# test_dataset['path'] = []\n",
    "# test_dataset['labels'] = []\n",
    "\n",
    "# for patch_rel_paths, img_labels in tqdm(zip(test_paths, test_labels)):\n",
    "#     for patch_rel_path in patch_rel_paths:\n",
    "#         test_dataset['path'] += [patch_rel_path]\n",
    "#         test_dataset['labels'] += [img_labels]\n",
    "\n",
    "# test_dataset['path'] = np.asarray(test_dataset['path']).flatten()\n",
    "# test_dataset['labels'] = np.asarray(test_dataset['labels']).flatten()\n",
    "\n",
    "# print('Saving training patches dataset to: {:}'.format(train_db_path))\n",
    "# np.save(train_db_path, train_dataset)\n",
    "# print('Saving testing patches dataset to: {:}'.format(test_db_path))\n",
    "# np.save(test_db_path, test_dataset)\n",
    "\n",
    "print('Completed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
