{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import warnings\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from skimage import io\n",
    "from params import dresden_images_root, images_db_path, patch_span, \\\n",
    "        patch_num, patches_root, train_db_path, test_db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agfa_DC-504 in training set: 139.\n",
      "Agfa_DC-504 in test set: 30.\n",
      "\n",
      "Agfa_DC-733s in training set: 214.\n",
      "Agfa_DC-733s in test set: 67.\n",
      "\n",
      "Agfa_DC-830i in training set: 289.\n",
      "Agfa_DC-830i in test set: 74.\n",
      "\n",
      "Agfa_Sensor505-x in training set: 141.\n",
      "Agfa_Sensor505-x in test set: 31.\n",
      "\n",
      "Agfa_Sensor530s in training set: 295.\n",
      "Agfa_Sensor530s in test set: 77.\n",
      "\n",
      "Canon_Ixus55 in training set: 187.\n",
      "Canon_Ixus55 in test set: 37.\n",
      "\n",
      "Canon_Ixus70 in training set: 456.\n",
      "Canon_Ixus70 in test set: 111.\n",
      "\n",
      "Canon_PowerShotA640 in training set: 148.\n",
      "Canon_PowerShotA640 in test set: 40.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images_db = np.load(images_db_path, allow_pickle=True).item()\n",
    "\n",
    "model_list = np.unique(images_db['brand_model'])\n",
    "\n",
    "img_list = os.listdir(dresden_images_root)\n",
    "num_test = int(len(img_list) * 0.2)\n",
    "num_train = int(len(img_list) - num_test)\n",
    "\n",
    "shuffle_list = np.random.permutation(img_list)\n",
    "\n",
    "train_list = shuffle_list[0:num_train].tolist()\n",
    "test_list = shuffle_list[num_train:].tolist()\n",
    "\n",
    "for model in model_list:\n",
    "    tmp_list = fnmatch.filter(train_list, model + '*')\n",
    "    print(\"{} in training set: {}.\".format(model, len(tmp_list)))\n",
    "    tmp_list = fnmatch.filter(test_list, model + '*')\n",
    "    print(\"{} in test set: {}.\\n\".format(model, len(tmp_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(img_name, patch_span, pacth_size=(256, 256)):\n",
    "    img = io.imread(img_name)\n",
    "    if img is None or not isinstance(img, np.ndarray):\n",
    "        print('Unable to read the image: {:}'.format(args['img_path']))\n",
    "\n",
    "    center = np.divide(img.shape[:2], 2).astype(int)\n",
    "    start = np.subtract(center, patch_span/2).astype(int)\n",
    "    end = np.add(center, patch_span/2).astype(int)\n",
    "    sub_img = img[start[0]:end[0], start[1]:end[1]]\n",
    "    patches = view_as_blocks(sub_img[:, :, 1], (256, 256))\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save(args):\n",
    "    # 'Agfa/DC-504/Agfa_DC-504_0_1/Agfa_DC-504_0_1_00.png' for example,\n",
    "    # last part is the patch idex.\n",
    "    output_rel_paths = [os.path.join(args['data_set'], args['img_brand_model'],\n",
    "                        os.path.splitext(os.path.split(args['img_path'])[-1])[0]+'_'+'{:02}'.format(patch_idx) + '.png')\\\n",
    "                        for patch_idx in range(args['patch_num'])]\n",
    "    read_img = False\n",
    "    for out_path in output_rel_paths:\n",
    "        out_fullpath = os.path.join(args['patch_root'], out_path)\n",
    "        # if there is no this path, then we have to read images\n",
    "        if not os.path.exists(out_fullpath):\n",
    "            read_img = True\n",
    "            break\n",
    "    if read_img:\n",
    "        img_name = os.path.join(args['img_root'], args['img_path'])\n",
    "        patches = patchify(img_name, args['patch_span']).reshape((-1, 256, 256))\n",
    "        \n",
    "        for out_path, patch in zip(output_rel_paths, patches):\n",
    "            out_fullpath = os.path.join(args['patch_root'],out_path)\n",
    "            # the diretory of the patches images\n",
    "            out_fulldir = os.path.split(out_fullpath)[0]\n",
    "            if not os.path.exists(out_fulldir):\n",
    "                os.makedirs(out_fulldir)\n",
    "            if not os.path.exists(out_fullpath):\n",
    "                io.imsave(out_fullpath, patch)\n",
    "\n",
    "    return output_rel_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_labels = dict(zip(images_db['path'], images_db['brand_model']))\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "for path in train_list:\n",
    "    train_labels += [files_labels[path]]\n",
    "    \n",
    "for path in test_list:\n",
    "    test_labels += [files_labels[path]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2336it [00:00, 47928.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image data...\n",
      "Extracting patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "print('Collecting image data...')\n",
    "\n",
    "train_imgs_list = []\n",
    "test_imgs_list = []\n",
    "\n",
    "for img_brand_model,img_path in \\\n",
    "    tqdm(zip(images_db['brand_model'], images_db['path'])):\n",
    "                   \n",
    "    if img_path in train_list:\n",
    "        train_imgs_list += [{'data_set':'train',\n",
    "                           'img_path':img_path,\n",
    "                           'img_brand_model':img_brand_model,\n",
    "                           'patch_span':patch_span,\n",
    "                           'patch_num':patch_num,\n",
    "                           'patch_root': patches_root,\n",
    "                           'img_root': dresden_images_root\n",
    "                           }]\n",
    "    else:\n",
    "        test_imgs_list += [{'data_set':'test',\n",
    "                           'img_path':img_path,\n",
    "                           'img_brand_model':img_brand_model,\n",
    "                           'patch_span':patch_span,\n",
    "                           'patch_num':patch_num,\n",
    "                           'patch_root': patches_root,\n",
    "                           'img_root': dresden_images_root\n",
    "                           }]\n",
    "    \n",
    "print('Extracting patches...')\n",
    "\n",
    "num_processes = 12\n",
    "pool = Pool(processes=num_processes)\n",
    "train_paths = pool.map(extract_and_save, train_imgs_list)\n",
    "test_paths = pool.map(extract_and_save, test_imgs_list)\n",
    "\n",
    "# # Create patches dataset\n",
    "# print('Creating patches dataset...')\n",
    "# train_dataset = dict()\n",
    "# train_dataset['path'] = []\n",
    "# train_dataset['labels'] = []\n",
    "\n",
    "# for patch_rel_paths, img_labels in tqdm(zip(train_paths, train_labels)):\n",
    "#     for patch_rel_path in patch_rel_paths:\n",
    "#         train_dataset['path'] += [patch_rel_path]\n",
    "#         train_dataset['labels'] += [img_labels]\n",
    "\n",
    "# train_dataset['path'] = np.asarray(train_dataset['path']).flatten()\n",
    "# train_dataset['shot'] = np.asarray(train_dataset['labels']).flatten()\n",
    "        \n",
    "# test_dataset = dict()\n",
    "# test_dataset['path'] = []\n",
    "# test_dataset['labels'] = []\n",
    "\n",
    "# for patch_rel_paths, img_labels in tqdm(zip(test_paths, test_labels)):\n",
    "#     for patch_rel_path in patch_rel_paths:\n",
    "#         test_dataset['path'] += [patch_rel_path]\n",
    "#         test_dataset['labels'] += [img_labels]\n",
    "\n",
    "# test_dataset['path'] = np.asarray(test_dataset['path']).flatten()\n",
    "# test_dataset['labels'] = np.asarray(test_dataset['labels']).flatten()\n",
    "\n",
    "# print('Saving training patches dataset to: {:}'.format(train_db_path))\n",
    "# np.save(train_db_path, train_dataset)\n",
    "# print('Saving testing patches dataset to: {:}'.format(test_db_path))\n",
    "# np.save(test_db_path, test_dataset)\n",
    "\n",
    "print('Completed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
