{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import fnmatch\n",
    "import time\n",
    "import split_extract\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from params import dresden_images_root, images_db_path, patch_span, \\\n",
    "        patch_num, unseen_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists(unseen_root):\n",
    "    os.makedirs(unseen_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real models: Canon_Ixus55, Canon_Ixus70, Canon_PowerShotA640\n",
      "test models: Nikon_CoolPixS710, Nikon_D200, Nikon_D70, Nikon_D70s, Sony_DSC-H50, Sony_DSC-T77, Sony_DSC-W170\n",
      "Nikon_CoolPixS710 in test set: 925.\n",
      "Nikon_D200 in test set: 752.\n",
      "Nikon_D70 in test set: 736.\n",
      "Nikon_D70s in test set: 367.\n",
      "Sony_DSC-H50 in test set: 541.\n",
      "Sony_DSC-T77 in test set: 725.\n",
      "Sony_DSC-W170 in test set: 405.\n"
     ]
    }
   ],
   "source": [
    "images_db = np.load(images_db_path, allow_pickle=True).item()\n",
    "# read all the trained model images and unseen model images\n",
    "real_model_list = list(filter(lambda model: re.search(r'Canon*', model), images_db['brand_model']))\n",
    "test_model_list = list(filter(lambda model: re.search(r'^((?!Canon).)*$', model), images_db['brand_model']))\n",
    "test_img_list = list(filter(lambda img: re.search(r'^((?!Canon).)*$', img), images_db['path']))\n",
    "\n",
    "# How many model in my dataset, real are trained models, test are unseen models\n",
    "real_model = np.unique(real_model_list) \n",
    "test_model = np.unique(test_model_list) \n",
    "print(\"real models: {}\".format(', '.join(real_model)))\n",
    "print(\"test models: {}\".format(', '.join(test_model)))\n",
    "\n",
    "for model in test_model:\n",
    "    tmp_list = fnmatch.filter(test_model_list, model + '*')\n",
    "    print(\"{} in test set: {}.\".format(model, len(tmp_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "for img_brand_model, img_path in zip(test_model_list, test_img_list):\n",
    "        test_list += [{'data_set':'test',\n",
    "                       'img_path':img_path,\n",
    "                       'img_brand_model':img_brand_model,\n",
    "                       'patch_span':patch_span,\n",
    "                       'patch_num':patch_num,\n",
    "                       'patch_root': unseen_root,\n",
    "                       'img_root': dresden_images_root\n",
    "                       }]\n",
    "\n",
    "num_processes = 12\n",
    "pool = Pool(processes=num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = pool.map(split_extract.extract, test_list)\n",
    "print('Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image and batch size\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "batch_size = 64\n",
    "\n",
    "# Load and Compile the model\n",
    "model = tf.keras.models.load_model('./instance/model.h5')\n",
    "test_data_gen = ImageDataGenerator(preprocessing_function=None,\n",
    "    rescale=1./255)\n",
    "# Read the positive test samples.\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "                  directory = r\"./unseen/test/\",\n",
    "                  target_size=(img_width, img_height), color_mode='grayscale', shuffle=True,\n",
    "                  batch_size=batch_size, class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a histogram, which for every unseen models, how many imgs are classified.\n",
    "t0 = time.time()\n",
    "hist = [[0, 0, 0] for i in range(len(test_model))]\n",
    "conf = []\n",
    "\n",
    "for i in range(200):\n",
    "    gen = next(test_generator)\n",
    "    pred = model.predict(gen[0])\n",
    "    conf.append(pred)\n",
    "    pred_labels = np.argmax(pred, axis=1)\n",
    "    real_labels = np.argmax(gen[1], axis=1)\n",
    "    for j in range(len(pred_labels)):\n",
    "        hist[real_labels[j]][pred_labels[j]] += 1\n",
    "t1 = time.time()\n",
    "print('It tooks {:d} seconds'.format(int(t1-t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hist, index=test_model, columns=real_model)\n",
    "print(df)\n",
    "df.plot.bar(stacked=True, figsize=(10, 5), title='Classify Nikon and Sony with trained Canon Model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
